## AUC与正负例比例 ##

### 变量定义 ###

- **P** 正例数 = TP + FN
- **TP** True Positive
- **FP** False Positive
- **N** 负例数 = TN + FP
- **TN** True Negtive
- **FN** False Negtive
- **TPR** True Positive Rate = TP / P
- **FPR** False Positive Rate = FP / N

### 黎曼法计算AUC ###

**ROC曲线** 是正负例辨别阈值在(TPR, FPR)空间内形成的曲线。  
**AUC** 是ROC曲线下的面积，可以用黎曼法计算。

考虑{0, 1}分类问题，首先假设数据量N足够大，将[0,1]的预测值域等为K个bin，计算每一份中的TP、FPi，从高到低计算每个bin对应的TPR。第k个bin对应在黎曼积分中的矩形宽度为FPk/N，高度为TPR。将这些矩形的面积相加便得到AUC。

---

### 对测试集中的正例均匀抽样不会改变AUC ###

现在考虑只对测试集中的正例进行抽样，以改变正负例的比例。在样本量足够大的前提下，任何均匀抽样不会改变正例在各个bin中的分布比率，也就不会改变每个bin对应的TPR。而每个bin中的FP也不会改变。因此正负例的判断标准不变的情况下，均匀抽样不会改变最终的AUC。

### 对训练集和测试集中正例均匀抽样不会改变AUC ###

对训练集中的正例进行均匀抽样，不会改变正样本在特征空间中的分布，正样本描述的空间区域不会改变，也就不会改变分界面的位置和形状，就是说模型不会变。那么这种情况同上。只有当数据量不足的时候，对正例抽样会使分界面变的模糊，信噪比降低，降低模型的效果，导致AUC降低。

### 同理对负例进行均匀抽样也不会改变AUC ###

---

### 改变测试集中正例的定义 ###

通过改变正负标注的定义，使一部分接近于负例的正例变为负例。先只考虑本来是正例的这部分样本，在新的正例定义下，变成了一个新的分类问题。原模型给出的分数同样会让这部分样本有一个序关系，假设原来的模型对于这一新的分类问题有大于0.5的AUC。那么考虑黎曼积分中的那K个bin，分值低的bin中正例变为负例的比例会比分值高的bin中大。显然ROC曲线会向左上漂移，AUC会升高。

### 同时改变训练集和测试集中正例的定义 ###

从经验上有个最简单的解释：数据量足够的前提下，训练集和测试集中正负标注采用相同定义的时候，模型的效果要比采用不同定义的时候好。因此这种情况的AUC一般会比上面一种情况更高。


### 因此 ###

AUC的高低是相对的，不同问题的AUC不具有绝对的可比性。当改变一个问题中正负样本的定义的时候，相当于改变了一个问题，AUC的提高不代表模型效果的提升。

---

### CTR预估中的AUC ###

在CTR预估中有一些经典的场景会给人一种错觉：正例占比越低，AUC越高。其实这种现象来自于正负label定义的差别。

举个例子，在搜索广告（banner）中，有两种经典的CTR预估问题：

- 问题1：通用CTR预估，即对整个广告点击率的预估
- 问题2：广告中某一子链的CTR预估

一般来说相同的环境中，问题2会的到比问题1更高的AUC。这个差别来自于label定义的不同。问题2中的正例是问题1中正例的真子集，同时由于子链面积更小，能够排除更多的误点，因此问题2其实相当于在问题1的基础上将一些更像负例的正例划分到了负例之中。